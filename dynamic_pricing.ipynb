{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnDM15i6z2FG"
      },
      "source": [
        "## **Dynamic Pricing Model**:\n",
        "We have calculated dynamic pricing model that smartly adjusts costs, enticing visits during quieter times, enhancing peace without breaking the bank."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZUpSPx4zu9b"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Assume base prices\n",
        "base_prices = {\n",
        "    'Blue Lagoon': 50,\n",
        "    'Machu Picchu': 70,\n",
        "    'Taj Mahal': 40,\n",
        "    'Doge\\'s Palace': 55,\n",
        "    'Louvre Museum': 65\n",
        "}\n",
        "\n",
        "# make data\n",
        "data = pd.read_csv('/content/drive/MyDrive/ForwardKeys_data.csv')\n",
        "data['Date'] = pd.to_datetime(data['Date'])\n",
        "data['DayOfWeek'] = data['Date'].dt.dayofweek\n",
        "data['Month'] = data['Date'].dt.month\n",
        "data['Hour'] = pd.to_datetime(data['Time'], format='%H:%M').dt.hour\n",
        "\n",
        "# Louvre Museum is target variable \n",
        "X = data[['DayOfWeek', 'Month', 'Hour']]  \n",
        "y = data['Visitors in Louvre Museum']\n",
        "\n",
        "# split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# train RFM\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict visitors\n",
        "predicted_counts = model.predict(X_test)\n",
        "\n",
        "# eva\n",
        "mse = mean_squared_error(y_test, predicted_counts)\n",
        "rmse = np.sqrt(mse)  # Square root of MSE gives us RMSE\n",
        "\n",
        "# Calculate R-squared\n",
        "r_squared = r2_score(y_test, predicted_counts)\n",
        "\n",
        "print(f'Mean Squared Error: {mse}')\n",
        "print(f'Root Mean Squared Error: {rmse}')\n",
        "print(f'R-squared: {r_squared}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwywlOh45z1W",
        "outputId": "10f8afe0-a119-4140-ac6c-f15b941fcb63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[52.0, 52.0, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 78.0, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 78.0, 65, 65, 65, 65, 52.0, 52.0, 65, 65, 65, 65, 52.0, 52.0, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 52.0, 52.0, 52.0, 65, 65, 65, 65, 65, 52.0, 65, 65, 65, 65, 65, 65, 52.0, 78.0, 65, 65, 65, 65, 65, 65, 65, 65, 52.0, 65, 65, 65, 65, 65, 65, 65, 65, 65, 52.0, 65, 65, 52.0, 65, 65, 65, 65, 65, 65, 65, 65, 65, 52.0, 65, 65, 65, 65, 78.0, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 52.0, 65, 52.0, 65, 65, 52.0, 65, 65, 52.0, 52.0, 65, 65, 52.0, 65, 65, 52.0, 65, 65, 52.0, 65, 52.0, 52.0, 65, 65, 65, 65, 65, 65, 65, 65, 65, 52.0, 65, 65, 65, 65, 65, 65, 52.0, 65, 65, 52.0, 52.0, 65, 65, 52.0, 52.0, 65, 65, 65, 65, 65, 65, 65, 52.0, 65, 65, 65, 52.0, 65, 65, 65, 52.0, 65, 52.0, 65, 52.0, 65, 52.0, 65, 52.0, 65, 65, 65, 65, 65, 65, 65, 52.0, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 52.0, 65, 65, 65, 65, 65, 65, 65, 65, 52.0, 52.0, 65, 65, 52.0, 65, 65, 65, 52.0, 52.0, 52.0, 65, 65, 65, 52.0, 65, 65, 65, 65, 65, 52.0, 52.0, 65, 65, 65, 65, 65, 65, 65, 65, 65, 52.0, 65, 65, 65, 65, 65, 52.0, 65, 65, 65, 52.0, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 52.0, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 52.0, 52.0, 65, 65, 65, 65, 65, 65, 65, 78.0, 65, 78.0, 65, 52.0, 65, 65, 52.0, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 78.0, 65, 65, 65, 65, 65, 65, 65, 65, 65, 52.0, 65, 65, 65, 52.0, 65, 52.0, 65, 65, 52.0, 52.0, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 78.0, 65, 52.0, 65, 65, 65, 65, 65, 65, 65, 78.0, 78.0, 65, 65, 65, 52.0, 78.0, 65, 65, 65, 65, 65, 52.0, 65, 65, 65, 52.0, 65, 65, 65, 78.0, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 52.0, 65, 65, 65, 65, 65, 65, 65, 52.0, 65, 65, 65, 65, 65, 65, 65, 52.0, 52.0, 65, 65, 65, 65, 65, 65, 52.0, 65, 65, 65, 65, 65, 65, 78.0, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 52.0, 65, 52.0, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 52.0, 65, 52.0, 65, 65, 65, 65, 65, 65, 65, 52.0, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 52.0, 65, 65, 65, 65, 65, 52.0, 65, 52.0, 65, 52.0, 65, 65, 78.0, 65, 65, 65, 65, 52.0, 65, 65, 52.0, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 52.0, 65, 65, 65, 65, 52.0, 52.0, 65, 65, 65, 65, 52.0, 52.0, 65, 65, 65, 65, 65, 52.0, 52.0, 65, 65, 52.0, 52.0, 65, 65, 78.0, 65, 65, 65, 65, 65, 65, 65, 65, 52.0, 65, 65, 65, 65, 52.0, 65, 52.0, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 78.0, 52.0, 65, 52.0, 65, 65, 78.0, 65, 65, 65, 65, 78.0, 65, 65, 52.0, 65, 65, 65, 65, 65, 65, 52.0, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 52.0, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 52.0, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 52.0, 65, 65, 65, 65, 65, 65, 65, 78.0, 65, 65, 52.0, 65, 52.0, 65, 65, 52.0, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 52.0, 65, 65, 65, 65, 52.0, 65, 52.0, 65, 65, 52.0, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 78.0, 65, 65, 65, 65, 65, 65, 65, 52.0, 65, 52.0, 65, 65, 65, 65, 65, 65, 65, 65, 65, 52.0, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 52.0, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 78.0, 65, 52.0, 52.0, 65, 65, 65, 65, 52.0, 65, 52.0, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 52.0, 65, 65, 65, 65, 65, 52.0, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 52.0, 65, 65, 52.0, 65, 65, 65, 78.0, 65, 65, 65, 65, 65, 52.0, 52.0, 65, 65, 65, 65, 65, 65, 65, 65, 65, 52.0, 65, 65, 65, 65, 52.0, 65, 52.0, 65, 65, 65, 65, 52.0, 65, 65, 65, 65, 65, 65, 65, 52.0, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 52.0, 65, 65, 65, 65, 65, 65, 52.0, 65, 65, 65, 52.0, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 52.0, 65, 52.0, 65, 65, 65, 65, 65, 78.0, 65, 65, 52.0, 52.0, 65, 65, 65, 65, 52.0, 65, 52.0, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 52.0, 52.0, 65, 65, 65, 65, 65, 65, 65, 65, 65, 52.0, 65, 65, 65, 52.0, 65, 65, 65, 65, 52.0, 65, 65, 65, 65, 65, 65, 65]\n"
          ]
        }
      ],
      "source": [
        "# Predict visitors \n",
        "predicted_visitors = model.predict(X_test)\n",
        "\n",
        "# Determine price adjustment thresholds\n",
        "visitor_threshold_high = np.percentile(y_train, 75)\n",
        "visitor_threshold_low = np.percentile(y_train, 25)\n",
        "\n",
        "# Adjust prices \n",
        "dynamic_prices = []\n",
        "for visitors in predicted_visitors:\n",
        "    if visitors > visitor_threshold_high:\n",
        "        price = base_prices['Louvre Museum'] * 1.2  # Increase price by 20%\n",
        "    elif visitors < visitor_threshold_low:\n",
        "        price = base_prices['Louvre Museum'] * 0.8  # Decrease price by 20%\n",
        "    else:\n",
        "        price = base_prices['Louvre Museum']\n",
        "    dynamic_prices.append(price)\n",
        "\n",
        "print(dynamic_prices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBtZeNgbB7ed",
        "outputId": "d78854c2-a051-4701-dfe8-a72a58773a37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSE: 77761423.17375948\n",
            "R^2 Score: 0.17357545935504237\n"
          ]
        }
      ],
      "source": [
        "# Create a linear regression model\n",
        "model_lr = LinearRegression()\n",
        "model_lr.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the testing set\n",
        "predictions_lr = model_lr.predict(X_test)\n",
        "\n",
        "# eva model\n",
        "mse_lr = mean_squared_error(y_test, predictions_lr)\n",
        "r2_lr = r2_score(y_test, predictions_lr)\n",
        "print(\"MSE:\", mse_lr)\n",
        "print(\"R^2 Score:\", r2_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7vTHbDNCPmf",
        "outputId": "2559cdda-b54f-4d2d-a779-ef591f1d790b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[52.0, 52.0, 65, 65, 65, 65, 65, 65, 65, 65, 52.0, 65, 65, 65, 65, 65, 65, 65, 52.0, 65, 52.0, 65, 65, 65, 52.0, 65, 52.0, 65, 65, 65, 52.0, 65, 65, 52.0, 52.0, 52.0, 52.0, 65, 52.0, 65, 65, 52.0, 52.0, 65, 52.0, 65, 65, 65, 65, 65, 65, 65, 52.0, 65, 65, 52.0, 52.0, 52.0, 52.0, 65, 65, 65, 65, 65, 52.0, 65, 65, 52.0, 52.0, 65, 52.0, 52.0, 65, 65, 65, 65, 65, 65, 65, 65, 65, 52.0, 52.0, 65, 65, 52.0, 52.0, 52.0, 65, 65, 65, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 65, 65, 65, 65, 52.0, 65, 52.0, 52.0, 65, 52.0, 65, 65, 65, 65, 65, 65, 65, 65, 65, 52.0, 65, 52.0, 65, 52.0, 65, 52.0, 65, 65, 52.0, 65, 65, 52.0, 52.0, 65, 65, 52.0, 65, 52.0, 52.0, 65, 52.0, 52.0, 65, 52.0, 52.0, 65, 65, 52.0, 65, 65, 65, 52.0, 52.0, 52.0, 52.0, 65, 65, 65, 65, 65, 65, 52.0, 52.0, 52.0, 52.0, 52.0, 65, 65, 52.0, 52.0, 65, 65, 52.0, 65, 65, 65, 65, 52.0, 65, 65, 65, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 65, 52.0, 65, 52.0, 65, 52.0, 65, 65, 65, 65, 65, 65, 52.0, 52.0, 65, 65, 52.0, 52.0, 52.0, 65, 52.0, 65, 52.0, 52.0, 52.0, 65, 65, 65, 52.0, 52.0, 65, 52.0, 65, 52.0, 52.0, 65, 65, 52.0, 65, 65, 52.0, 52.0, 52.0, 52.0, 52.0, 65, 52.0, 52.0, 52.0, 52.0, 52.0, 65, 65, 52.0, 52.0, 65, 65, 65, 52.0, 65, 52.0, 52.0, 52.0, 65, 65, 65, 52.0, 65, 65, 65, 65, 52.0, 52.0, 65, 65, 52.0, 65, 52.0, 65, 52.0, 52.0, 52.0, 65, 65, 65, 65, 52.0, 65, 65, 52.0, 65, 65, 65, 52.0, 65, 52.0, 65, 65, 65, 65, 65, 65, 65, 65, 52.0, 52.0, 65, 65, 65, 52.0, 65, 52.0, 65, 65, 52.0, 65, 65, 52.0, 52.0, 65, 52.0, 65, 52.0, 65, 65, 65, 52.0, 52.0, 52.0, 65, 65, 52.0, 65, 52.0, 65, 65, 65, 52.0, 65, 65, 65, 65, 52.0, 52.0, 65, 65, 52.0, 52.0, 52.0, 65, 52.0, 52.0, 52.0, 65, 65, 65, 52.0, 65, 52.0, 65, 65, 65, 65, 52.0, 65, 65, 52.0, 52.0, 65, 52.0, 65, 65, 65, 65, 52.0, 65, 65, 65, 52.0, 65, 52.0, 65, 52.0, 65, 65, 65, 65, 52.0, 65, 52.0, 52.0, 52.0, 65, 65, 65, 65, 65, 52.0, 65, 65, 65, 65, 65, 65, 65, 65, 52.0, 65, 65, 65, 65, 52.0, 65, 65, 52.0, 65, 52.0, 65, 65, 65, 65, 52.0, 52.0, 65, 52.0, 65, 65, 65, 52.0, 52.0, 65, 65, 52.0, 52.0, 65, 65, 52.0, 65, 65, 65, 52.0, 65, 65, 65, 52.0, 52.0, 65, 52.0, 65, 65, 65, 65, 65, 65, 65, 52.0, 65, 65, 52.0, 65, 52.0, 52.0, 65, 65, 65, 52.0, 52.0, 65, 65, 65, 65, 65, 52.0, 65, 52.0, 52.0, 52.0, 65, 65, 52.0, 52.0, 65, 52.0, 65, 65, 52.0, 65, 65, 52.0, 65, 65, 65, 65, 65, 65, 65, 65, 52.0, 65, 52.0, 65, 65, 65, 52.0, 65, 52.0, 52.0, 52.0, 65, 65, 65, 65, 52.0, 65, 52.0, 52.0, 65, 65, 52.0, 52.0, 65, 65, 52.0, 65, 65, 52.0, 65, 52.0, 65, 52.0, 52.0, 52.0, 65, 52.0, 65, 65, 52.0, 52.0, 65, 52.0, 52.0, 52.0, 65, 52.0, 52.0, 65, 52.0, 65, 65, 52.0, 52.0, 65, 65, 52.0, 65, 52.0, 52.0, 52.0, 65, 65, 65, 65, 52.0, 52.0, 65, 52.0, 52.0, 52.0, 65, 65, 65, 65, 65, 65, 65, 65, 52.0, 65, 52.0, 52.0, 52.0, 65, 65, 52.0, 52.0, 65, 52.0, 52.0, 65, 52.0, 65, 65, 65, 65, 65, 65, 52.0, 65, 65, 52.0, 52.0, 52.0, 52.0, 65, 65, 65, 65, 65, 65, 52.0, 65, 65, 52.0, 65, 65, 65, 65, 65, 65, 52.0, 65, 65, 52.0, 52.0, 65, 65, 52.0, 65, 65, 65, 52.0, 65, 52.0, 65, 52.0, 65, 65, 65, 65, 65, 65, 65, 52.0, 65, 65, 65, 65, 65, 65, 65, 65, 52.0, 65, 65, 52.0, 65, 65, 65, 65, 65, 65, 65, 52.0, 65, 65, 52.0, 65, 52.0, 65, 52.0, 52.0, 65, 65, 52.0, 65, 52.0, 65, 65, 65, 65, 65, 52.0, 65, 65, 52.0, 52.0, 52.0, 65, 52.0, 65, 52.0, 52.0, 52.0, 65, 65, 52.0, 65, 65, 52.0, 65, 52.0, 65, 65, 65, 65, 52.0, 65, 65, 65, 52.0, 65, 52.0, 65, 52.0, 52.0, 52.0, 65, 65, 65, 52.0, 65, 65, 52.0, 52.0, 52.0, 52.0, 65, 65, 65, 65, 65, 52.0, 52.0, 65, 52.0, 52.0, 65, 52.0, 65, 65, 65, 52.0, 65, 65, 65, 65, 65, 65, 65, 52.0, 65, 65, 65, 65, 65, 52.0, 52.0, 52.0, 65, 65, 65, 65, 52.0, 52.0, 52.0, 52.0, 52.0, 65, 52.0, 65, 52.0, 65, 65, 52.0, 65, 65, 52.0, 65, 65, 65, 65, 52.0, 65, 52.0, 65, 52.0, 65, 65, 65, 52.0, 65, 52.0, 65, 52.0, 52.0, 65, 65, 52.0, 65, 52.0, 52.0, 52.0, 52.0, 65, 65, 52.0, 52.0, 65, 65, 65, 65, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 65, 65, 52.0, 52.0, 65, 65, 65, 52.0, 65, 52.0, 65, 65, 52.0, 65, 52.0, 65, 65, 65, 65, 52.0, 65, 65, 65, 52.0, 52.0, 65, 65, 52.0, 52.0, 52.0, 52.0, 65, 65, 65, 52.0, 52.0, 65, 52.0, 65, 52.0, 65, 65, 65, 52.0, 52.0, 52.0, 52.0, 52.0, 65, 65, 52.0, 65, 65, 65, 52.0, 65, 65, 65, 52.0, 65, 65, 52.0, 65, 52.0, 65, 52.0, 65, 65, 65, 65, 52.0, 52.0, 65, 52.0, 52.0, 52.0, 65, 65, 65, 52.0, 52.0, 52.0, 52.0, 52.0, 65, 52.0, 52.0, 65, 65, 65, 52.0, 65, 52.0, 52.0, 52.0, 65, 52.0, 65, 52.0, 65, 52.0, 52.0, 65, 65, 65, 65, 52.0, 65, 52.0, 52.0, 65, 52.0, 52.0, 52.0, 65, 52.0, 65, 65, 65, 52.0, 52.0, 65, 65, 65, 65, 52.0, 52.0, 52.0]\n"
          ]
        }
      ],
      "source": [
        "# Predict visitors\n",
        "predicted_visitors_lr = model_lr.predict(X_test)\n",
        "# Determine price adjustment thresholds\n",
        "visitor_threshold_high = np.percentile(y_train, 75)\n",
        "visitor_threshold_low = np.percentile(y_train, 25)\n",
        "\n",
        "# Adjust prices based on prediction\n",
        "dynamic_prices_lr = []\n",
        "for visitors in predicted_visitors_lr:\n",
        "    if visitors > visitor_threshold_high:\n",
        "        price = base_prices['Louvre Museum'] * 1.2  # Increase price by 20%\n",
        "    elif visitors < visitor_threshold_low:\n",
        "        price = base_prices['Louvre Museum'] * 0.8  # Decrease price by 20%\n",
        "    else:\n",
        "        price = base_prices['Louvre Museum']\n",
        "    dynamic_prices_lr.append(price)\n",
        "\n",
        "print(dynamic_prices_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYhAC-XDMUYG",
        "outputId": "3c4e0144-24dd-4eb8-e30c-216ffc04c1c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X shape: (4652, 3)\n",
            "hours_scaled shape: (4652, 1)\n",
            "Epoch 1/20\n",
            "117/117 - 3s - loss: 0.1170 - 3s/epoch - 26ms/step\n",
            "Epoch 2/20\n",
            "117/117 - 0s - loss: 0.0565 - 389ms/epoch - 3ms/step\n",
            "Epoch 3/20\n",
            "117/117 - 0s - loss: 0.0552 - 365ms/epoch - 3ms/step\n",
            "Epoch 4/20\n",
            "117/117 - 0s - loss: 0.0548 - 397ms/epoch - 3ms/step\n",
            "Epoch 5/20\n",
            "117/117 - 0s - loss: 0.0548 - 363ms/epoch - 3ms/step\n",
            "Epoch 6/20\n",
            "117/117 - 0s - loss: 0.0546 - 373ms/epoch - 3ms/step\n",
            "Epoch 7/20\n",
            "117/117 - 0s - loss: 0.0543 - 375ms/epoch - 3ms/step\n",
            "Epoch 8/20\n",
            "117/117 - 0s - loss: 0.0543 - 359ms/epoch - 3ms/step\n",
            "Epoch 9/20\n",
            "117/117 - 0s - loss: 0.0541 - 386ms/epoch - 3ms/step\n",
            "Epoch 10/20\n",
            "117/117 - 0s - loss: 0.0540 - 360ms/epoch - 3ms/step\n",
            "Epoch 11/20\n",
            "117/117 - 0s - loss: 0.0544 - 356ms/epoch - 3ms/step\n",
            "Epoch 12/20\n",
            "117/117 - 0s - loss: 0.0541 - 395ms/epoch - 3ms/step\n",
            "Epoch 13/20\n",
            "117/117 - 0s - loss: 0.0539 - 353ms/epoch - 3ms/step\n",
            "Epoch 14/20\n",
            "117/117 - 0s - loss: 0.0542 - 374ms/epoch - 3ms/step\n",
            "Epoch 15/20\n",
            "117/117 - 0s - loss: 0.0537 - 371ms/epoch - 3ms/step\n",
            "Epoch 16/20\n",
            "117/117 - 0s - loss: 0.0537 - 369ms/epoch - 3ms/step\n",
            "Epoch 17/20\n",
            "117/117 - 0s - loss: 0.0539 - 377ms/epoch - 3ms/step\n",
            "Epoch 18/20\n",
            "117/117 - 0s - loss: 0.0540 - 370ms/epoch - 3ms/step\n",
            "Epoch 19/20\n",
            "117/117 - 0s - loss: 0.0534 - 358ms/epoch - 3ms/step\n",
            "Epoch 20/20\n",
            "117/117 - 0s - loss: 0.0536 - 419ms/epoch - 4ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d27a8d49330>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "# Assume base prices\n",
        "base_prices = {\n",
        "    'Blue Lagoon': 50,\n",
        "    'Machu Picchu': 70,\n",
        "    'Taj Mahal': 40,\n",
        "    'Doge\\'s Palace': 55,\n",
        "    'Louvre Museum': 65\n",
        "}\n",
        "\n",
        "# Load and prepare data\n",
        "data = pd.read_csv('/content/drive/MyDrive/ForwardKeys_data.csv')\n",
        "data['Date'] = pd.to_datetime(data['Date'])\n",
        "data['DayOfWeek'] = data['Date'].dt.dayofweek\n",
        "data['Month'] = data['Date'].dt.month\n",
        "data['Hour'] = pd.to_datetime(data['Time'], format='%H:%M').dt.hour\n",
        "\n",
        "visitor_data = data['Visitors in Blue Lagoon'].values.reshape(-1, 1)\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "visitor_scaled = scaler.fit_transform(visitor_data)\n",
        "\n",
        "# Create dataset for LSTM\n",
        "def create_dataset(dataset, look_back=1):\n",
        "    X, Y = [], []\n",
        "    for i in range(len(dataset) - look_back - 1):\n",
        "        a = dataset[i:(i + look_back), 0]\n",
        "        X.append(a)\n",
        "        Y.append(dataset[i + look_back, 0])\n",
        "    return np.array(X), np.array(Y)\n",
        "\n",
        "look_back = 3\n",
        "X, y = create_dataset(visitor_scaled, look_back)\n",
        "\n",
        "# Include hour of day as a feature in LSTM\n",
        "hours_scaled = scaler.fit_transform(data['Hour'].values.reshape(-1, 1)[look_back:-1])  # Adjust slicing to align with X\n",
        "\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"hours_scaled shape:\", hours_scaled.shape)\n",
        "\n",
        "hours_scaled = hours_scaled.flatten()\n",
        "\n",
        "X = np.hstack((X, hours_scaled.reshape(hours_scaled.shape[0], 1)))  # Proper hstack with correct reshaping\n",
        "X = X.reshape((X.shape[0], look_back + 1, 1))\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build LSTM model\n",
        "model = Sequential([\n",
        "    LSTM(50, input_shape=(look_back + 1, 1), activation='relu'),\n",
        "    Dense(50, activation='relu'),\n",
        "    Dense(25, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# train model\n",
        "model.fit(X_train, y_train, epochs=20, batch_size=32, verbose=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8taMztoWO5dc",
        "outputId": "7c875e79-17bc-4126-f6a8-198315755a00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "30/30 [==============================] - 0s 2ms/step\n",
            "[50, 52.5, 52.5, 50, 52.5, 50, 50, 50, 52.5, 50, 50, 50, 50, 50, 50, 50, 52.5, 50, 50, 55.00000000000001, 50, 50, 50, 50, 55.00000000000001, 50, 55.00000000000001, 50, 50, 52.5, 50, 50, 50, 50, 50, 50, 55.00000000000001, 50, 50, 55.00000000000001, 50, 50, 50, 52.5, 52.5, 50, 50, 50, 50, 50, 52.5, 50, 55.00000000000001, 50, 50, 52.5, 50, 50, 52.5, 52.5, 50, 50, 50, 55.00000000000001, 50, 50, 50, 50, 50, 50, 50, 55.00000000000001, 50, 50, 52.5, 50, 52.5, 50, 52.5, 50, 50, 50, 50, 50, 50, 50, 50, 55.00000000000001, 50, 50, 50, 52.5, 52.5, 52.5, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 52.5, 55.00000000000001, 50, 50, 55.00000000000001, 50, 50, 50, 55.00000000000001, 52.5, 55.00000000000001, 52.5, 52.5, 50, 50, 50, 50, 50, 52.5, 52.5, 50, 50, 50, 52.5, 55.00000000000001, 50, 50, 52.5, 50, 50, 50, 52.5, 50, 52.5, 50, 50, 50, 50, 55.00000000000001, 55.00000000000001, 50, 50, 50, 50, 50, 50, 50, 55.00000000000001, 50, 52.5, 50, 52.5, 50, 52.5, 52.5, 50, 50, 55.00000000000001, 55.00000000000001, 50, 55.00000000000001, 50, 50, 50, 50, 52.5, 55.00000000000001, 50, 52.5, 55.00000000000001, 50, 50, 50, 55.00000000000001, 50, 50, 50, 50, 50, 50, 50, 52.5, 50, 50, 50, 50, 50, 52.5, 55.00000000000001, 50, 50, 50, 50, 50, 52.5, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 52.5, 50, 50, 55.00000000000001, 50, 50, 50, 50, 50, 52.5, 50, 52.5, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 52.5, 52.5, 50, 50, 50, 52.5, 50, 52.5, 50, 52.5, 55.00000000000001, 52.5, 52.5, 55.00000000000001, 50, 55.00000000000001, 50, 55.00000000000001, 50, 52.5, 50, 50, 50, 50, 50, 50, 55.00000000000001, 50, 50, 50, 52.5, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 52.5, 50, 50, 52.5, 50, 50, 50, 50, 50, 50, 50, 50, 52.5, 52.5, 50, 50, 52.5, 55.00000000000001, 50, 50, 50, 50, 50, 50, 52.5, 50, 50, 50, 50, 50, 52.5, 50, 50, 52.5, 50, 50, 50, 55.00000000000001, 52.5, 55.00000000000001, 50, 50, 50, 50, 50, 52.5, 50, 50, 50, 50, 50, 52.5, 52.5, 50, 52.5, 50, 50, 50, 50, 50, 52.5, 55.00000000000001, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 52.5, 50, 50, 55.00000000000001, 50, 55.00000000000001, 50, 50, 55.00000000000001, 52.5, 52.5, 50, 55.00000000000001, 50, 50, 50, 50, 52.5, 50, 52.5, 50, 50, 50, 50, 50, 50, 50, 50, 52.5, 55.00000000000001, 50, 50, 50, 50, 55.00000000000001, 50, 55.00000000000001, 50, 52.5, 50, 50, 50, 52.5, 52.5, 50, 50, 52.5, 50, 50, 50, 50, 50, 50, 50, 52.5, 52.5, 50, 52.5, 50, 50, 50, 50, 50, 50, 50, 52.5, 50, 55.00000000000001, 50, 52.5, 50, 50, 50, 50, 50, 52.5, 52.5, 52.5, 55.00000000000001, 50, 50, 50, 50, 50, 52.5, 50, 50, 50, 50, 50, 55.00000000000001, 50, 50, 50, 50, 52.5, 52.5, 50, 52.5, 50, 55.00000000000001, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 55.00000000000001, 50, 50, 50, 55.00000000000001, 52.5, 50, 50, 50, 52.5, 50, 50, 52.5, 50, 55.00000000000001, 50, 55.00000000000001, 50, 50, 50, 50, 50, 50, 55.00000000000001, 50, 55.00000000000001, 50, 50, 50, 50, 50, 50, 50, 50, 50, 52.5, 50, 50, 50, 50, 50, 50, 50, 52.5, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 52.5, 55.00000000000001, 50, 50, 50, 52.5, 50, 50, 52.5, 50, 50, 52.5, 50, 50, 50, 50, 55.00000000000001, 50, 50, 52.5, 50, 50, 50, 50, 50, 50, 50, 52.5, 50, 50, 50, 50, 52.5, 50, 55.00000000000001, 50, 50, 55.00000000000001, 50, 50, 50, 50, 50, 50, 55.00000000000001, 50, 52.5, 50, 50, 50, 50, 50, 50, 50, 50, 50, 55.00000000000001, 52.5, 50, 50, 50, 52.5, 50, 55.00000000000001, 50, 50, 50, 50, 50, 52.5, 50, 50, 52.5, 50, 52.5, 50, 50, 50, 50, 50, 55.00000000000001, 52.5, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 52.5, 55.00000000000001, 50, 50, 55.00000000000001, 50, 52.5, 50, 50, 50, 50, 50, 52.5, 50, 52.5, 50, 50, 50, 50, 50, 52.5, 52.5, 50, 50, 52.5, 50, 52.5, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 52.5, 50, 50, 50, 50, 50, 50, 50, 50, 50, 52.5, 52.5, 50, 50, 50, 50, 50, 55.00000000000001, 50, 50, 50, 50, 52.5, 50, 50, 52.5, 50, 50, 50, 50, 50, 50, 55.00000000000001, 52.5, 52.5, 50, 50, 50, 50, 52.5, 50, 55.00000000000001, 55.00000000000001, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 52.5, 52.5, 55.00000000000001, 55.00000000000001, 50, 50, 50, 50, 55.00000000000001, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 52.5, 50, 52.5, 50, 52.5, 50, 50, 50, 50, 52.5, 50, 50, 50, 50, 52.5, 52.5, 50, 52.5, 55.00000000000001, 50, 50, 50, 50, 52.5, 50, 50, 50, 50, 50, 50, 50, 55.00000000000001, 50, 55.00000000000001, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 52.5, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 55.00000000000001, 50, 50, 50, 50, 50, 55.00000000000001, 50, 55.00000000000001, 52.5, 50, 50, 50, 50, 50, 50, 52.5, 50, 52.5, 50, 50, 50, 50, 55.00000000000001, 50, 50, 50, 52.5, 52.5, 50, 52.5, 50, 55.00000000000001, 50, 50, 50, 50, 50, 50, 55.00000000000001, 50, 50, 50, 50, 52.5, 50, 50, 50, 50, 55.00000000000001, 50, 50, 50, 50, 50, 50, 50, 52.5, 50, 52.5, 52.5, 52.5, 50, 50, 50, 50, 52.5, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 52.5, 52.5, 50, 55.00000000000001, 55.00000000000001, 50, 50, 50, 55.00000000000001, 50, 50, 50, 50, 50, 50, 50, 52.5, 50, 50, 50, 52.5, 50, 50, 50, 52.5, 50, 50, 50, 50, 55.00000000000001, 52.5, 52.5, 50, 50, 50, 50, 50, 55.00000000000001, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50]\n"
          ]
        }
      ],
      "source": [
        "# Predict and invert scaling\n",
        "predictions = model.predict(X_test)\n",
        "predictions = scaler.inverse_transform(predictions)\n",
        "test_hours = scaler.inverse_transform(X_test[:, -1, :]).flatten()\n",
        "\n",
        "# calculate dynamic price \n",
        "base_price = 50 \n",
        "dynamic_prices = []\n",
        "for pred, hour in zip(predictions.flatten(), test_hours):\n",
        "    if pred > np.percentile(predictions, 75):\n",
        "        price_adjustment = 1.1 if 10 <= hour <= 16 else 1.05 \n",
        "    else:\n",
        "        price_adjustment = 1  \n",
        "    dynamic_prices.append(base_price * price_adjustment)\n",
        "\n",
        "print(dynamic_prices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hOs2pBnv8PK",
        "outputId": "489acf1c-b780-4c18-d690-30e7a85f0681"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X shape: (4652, 3)\n",
            "hours_scaled shape: (4652, 1)\n",
            "Epoch 1/20\n",
            "117/117 - 3s - loss: 0.1485 - 3s/epoch - 23ms/step\n",
            "Epoch 2/20\n",
            "117/117 - 1s - loss: 0.0740 - 821ms/epoch - 7ms/step\n",
            "Epoch 3/20\n",
            "117/117 - 1s - loss: 0.0713 - 555ms/epoch - 5ms/step\n",
            "Epoch 4/20\n",
            "117/117 - 1s - loss: 0.0697 - 539ms/epoch - 5ms/step\n",
            "Epoch 5/20\n",
            "117/117 - 1s - loss: 0.0680 - 633ms/epoch - 5ms/step\n",
            "Epoch 6/20\n",
            "117/117 - 1s - loss: 0.0664 - 640ms/epoch - 5ms/step\n",
            "Epoch 7/20\n",
            "117/117 - 1s - loss: 0.0644 - 642ms/epoch - 5ms/step\n",
            "Epoch 8/20\n",
            "117/117 - 1s - loss: 0.0628 - 606ms/epoch - 5ms/step\n",
            "Epoch 9/20\n",
            "117/117 - 1s - loss: 0.0604 - 585ms/epoch - 5ms/step\n",
            "Epoch 10/20\n",
            "117/117 - 1s - loss: 0.0605 - 580ms/epoch - 5ms/step\n",
            "Epoch 11/20\n",
            "117/117 - 1s - loss: 0.0596 - 614ms/epoch - 5ms/step\n",
            "Epoch 12/20\n",
            "117/117 - 1s - loss: 0.0589 - 528ms/epoch - 5ms/step\n",
            "Epoch 13/20\n",
            "117/117 - 0s - loss: 0.0592 - 382ms/epoch - 3ms/step\n",
            "Epoch 14/20\n",
            "117/117 - 0s - loss: 0.0586 - 365ms/epoch - 3ms/step\n",
            "Epoch 15/20\n",
            "117/117 - 0s - loss: 0.0584 - 393ms/epoch - 3ms/step\n",
            "Epoch 16/20\n",
            "117/117 - 0s - loss: 0.0583 - 383ms/epoch - 3ms/step\n",
            "Epoch 17/20\n",
            "117/117 - 0s - loss: 0.0581 - 384ms/epoch - 3ms/step\n",
            "Epoch 18/20\n",
            "117/117 - 0s - loss: 0.0577 - 388ms/epoch - 3ms/step\n",
            "Epoch 19/20\n",
            "117/117 - 0s - loss: 0.0579 - 382ms/epoch - 3ms/step\n",
            "Epoch 20/20\n",
            "117/117 - 0s - loss: 0.0575 - 388ms/epoch - 3ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d27a8cf5180>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "# base prices\n",
        "base_prices = {\n",
        "    'Blue Lagoon': 50,\n",
        "    'Machu Picchu': 70,\n",
        "    'Taj Mahal': 40,\n",
        "    'Doge\\'s Palace': 55,\n",
        "    'Louvre Museum': 65\n",
        "}\n",
        "\n",
        "# make data\n",
        "data = pd.read_csv('/content/drive/MyDrive/ForwardKeys_data.csv')\n",
        "data['Date'] = pd.to_datetime(data['Date'])\n",
        "data['DayOfWeek'] = data['Date'].dt.dayofweek\n",
        "data['Month'] = data['Date'].dt.month\n",
        "data['Hour'] = pd.to_datetime(data['Time'], format='%H:%M').dt.hour\n",
        "\n",
        "visitor_data = data['Visitors in Machu Picchu'].values.reshape(-1, 1)\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "visitor_scaled = scaler.fit_transform(visitor_data)\n",
        "\n",
        "# Create dataset for LSTM\n",
        "def create_dataset(dataset, look_back=1):\n",
        "    X, Y = [], []\n",
        "    for i in range(len(dataset) - look_back - 1):\n",
        "        a = dataset[i:(i + look_back), 0]\n",
        "        X.append(a)\n",
        "        Y.append(dataset[i + look_back, 0])\n",
        "    return np.array(X), np.array(Y)\n",
        "\n",
        "look_back = 3\n",
        "X, y = create_dataset(visitor_scaled, look_back)\n",
        "\n",
        "# Include hour of day as a feature\n",
        "hours_scaled = scaler.fit_transform(data['Hour'].values.reshape(-1, 1)[look_back:-1])  # Adjust slicing to align with X\n",
        "\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"hours_scaled shape:\", hours_scaled.shape)\n",
        "\n",
        "hours_scaled = hours_scaled.flatten()\n",
        "X = np.hstack((X, hours_scaled.reshape(hours_scaled.shape[0], 1)))  # Proper hstack with correct reshaping\n",
        "X = X.reshape((X.shape[0], look_back + 1, 1))\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build lstm model\n",
        "model = Sequential([\n",
        "    LSTM(50, input_shape=(look_back + 1, 1), activation='relu'),\n",
        "    Dense(50, activation='relu'),\n",
        "    Dense(25, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# train model\n",
        "model.fit(X_train, y_train, epochs=20, batch_size=32, verbose=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzDK-zgJIewX",
        "outputId": "3c4f4399-de07-454d-f00b-a862fe3cb463"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[70, 73.5, 73.5, 70, 73.5, 70, 70, 70, 73.5, 70, 70, 70, 70, 70, 70, 70, 73.5, 70, 70, 77.0, 70, 70, 70, 70, 77.0, 70, 77.0, 70, 70, 73.5, 70, 70, 70, 70, 70, 70, 77.0, 70, 70, 77.0, 70, 70, 70, 73.5, 73.5, 70, 70, 70, 70, 70, 73.5, 70, 77.0, 70, 70, 73.5, 70, 70, 73.5, 73.5, 70, 70, 70, 77.0, 70, 70, 70, 70, 70, 70, 70, 77.0, 70, 70, 73.5, 70, 73.5, 70, 73.5, 70, 70, 70, 70, 70, 70, 70, 70, 77.0, 70, 70, 70, 73.5, 73.5, 73.5, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 73.5, 77.0, 70, 70, 77.0, 70, 70, 70, 77.0, 73.5, 77.0, 73.5, 73.5, 70, 70, 70, 70, 70, 73.5, 73.5, 70, 70, 70, 73.5, 77.0, 70, 70, 73.5, 70, 70, 70, 73.5, 70, 73.5, 70, 70, 70, 70, 77.0, 77.0, 70, 70, 70, 70, 70, 70, 70, 77.0, 70, 73.5, 70, 73.5, 70, 73.5, 73.5, 70, 70, 77.0, 77.0, 70, 77.0, 70, 70, 70, 70, 73.5, 77.0, 70, 73.5, 77.0, 70, 70, 70, 77.0, 70, 70, 70, 70, 70, 70, 70, 73.5, 70, 70, 70, 70, 70, 73.5, 77.0, 70, 70, 70, 70, 70, 73.5, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 73.5, 70, 70, 77.0, 70, 70, 70, 70, 70, 73.5, 70, 73.5, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 73.5, 73.5, 70, 70, 70, 73.5, 70, 73.5, 70, 73.5, 77.0, 73.5, 73.5, 77.0, 70, 77.0, 70, 77.0, 70, 73.5, 70, 70, 70, 70, 70, 70, 77.0, 70, 70, 70, 73.5, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 73.5, 70, 70, 73.5, 70, 70, 70, 70, 70, 70, 70, 70, 73.5, 73.5, 70, 70, 73.5, 77.0, 70, 70, 70, 70, 70, 70, 73.5, 70, 70, 70, 70, 70, 73.5, 70, 70, 73.5, 70, 70, 70, 77.0, 73.5, 77.0, 70, 70, 70, 70, 70, 73.5, 70, 70, 70, 70, 70, 73.5, 73.5, 70, 73.5, 70, 70, 70, 70, 70, 73.5, 77.0, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 73.5, 70, 70, 77.0, 70, 77.0, 70, 70, 77.0, 73.5, 73.5, 70, 77.0, 70, 70, 70, 70, 73.5, 70, 73.5, 70, 70, 70, 70, 70, 70, 70, 70, 73.5, 77.0, 70, 70, 70, 70, 77.0, 70, 77.0, 70, 73.5, 70, 70, 70, 73.5, 73.5, 70, 70, 73.5, 70, 70, 70, 70, 70, 70, 70, 73.5, 73.5, 70, 73.5, 70, 70, 70, 70, 70, 70, 70, 73.5, 70, 77.0, 70, 73.5, 70, 70, 70, 70, 70, 73.5, 73.5, 73.5, 77.0, 70, 70, 70, 70, 70, 73.5, 70, 70, 70, 70, 70, 77.0, 70, 70, 70, 70, 73.5, 73.5, 70, 73.5, 70, 77.0, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 77.0, 70, 70, 70, 77.0, 73.5, 70, 70, 70, 73.5, 70, 70, 73.5, 70, 77.0, 70, 77.0, 70, 70, 70, 70, 70, 70, 77.0, 70, 77.0, 70, 70, 70, 70, 70, 70, 70, 70, 70, 73.5, 70, 70, 70, 70, 70, 70, 70, 73.5, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 73.5, 77.0, 70, 70, 70, 73.5, 70, 70, 73.5, 70, 70, 73.5, 70, 70, 70, 70, 77.0, 70, 70, 73.5, 70, 70, 70, 70, 70, 70, 70, 73.5, 70, 70, 70, 70, 73.5, 70, 77.0, 70, 70, 77.0, 70, 70, 70, 70, 70, 70, 77.0, 70, 73.5, 70, 70, 70, 70, 70, 70, 70, 70, 70, 77.0, 73.5, 70, 70, 70, 73.5, 70, 77.0, 70, 70, 70, 70, 70, 73.5, 70, 70, 73.5, 70, 73.5, 70, 70, 70, 70, 70, 77.0, 73.5, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 73.5, 77.0, 70, 70, 77.0, 70, 73.5, 70, 70, 70, 70, 70, 73.5, 70, 73.5, 70, 70, 70, 70, 70, 73.5, 73.5, 70, 70, 73.5, 70, 73.5, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 73.5, 70, 70, 70, 70, 70, 70, 70, 70, 70, 73.5, 73.5, 70, 70, 70, 70, 70, 77.0, 70, 70, 70, 70, 73.5, 70, 70, 73.5, 70, 70, 70, 70, 70, 70, 77.0, 73.5, 73.5, 70, 70, 70, 70, 73.5, 70, 77.0, 77.0, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 73.5, 73.5, 77.0, 77.0, 70, 70, 70, 70, 77.0, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 73.5, 70, 73.5, 70, 73.5, 70, 70, 70, 70, 73.5, 70, 70, 70, 70, 73.5, 73.5, 70, 73.5, 77.0, 70, 70, 70, 70, 73.5, 70, 70, 70, 70, 70, 70, 70, 77.0, 70, 77.0, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 73.5, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 77.0, 70, 70, 70, 70, 70, 77.0, 70, 77.0, 73.5, 70, 70, 70, 70, 70, 70, 73.5, 70, 73.5, 70, 70, 70, 70, 77.0, 70, 70, 70, 73.5, 73.5, 70, 73.5, 70, 77.0, 70, 70, 70, 70, 70, 70, 77.0, 70, 70, 70, 70, 73.5, 70, 70, 70, 70, 77.0, 70, 70, 70, 70, 70, 70, 70, 73.5, 70, 73.5, 73.5, 73.5, 70, 70, 70, 70, 73.5, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 73.5, 73.5, 70, 77.0, 77.0, 70, 70, 70, 77.0, 70, 70, 70, 70, 70, 70, 70, 73.5, 70, 70, 70, 73.5, 70, 70, 70, 73.5, 70, 70, 70, 70, 77.0, 73.5, 73.5, 70, 70, 70, 70, 70, 77.0, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70]\n"
          ]
        }
      ],
      "source": [
        "# Calculate dynamic prices\n",
        "base_price = 70 \n",
        "dynamic_prices = []\n",
        "for pred, hour in zip(predictions.flatten(), test_hours):\n",
        "    if pred > np.percentile(predictions, 75):\n",
        "        price_adjustment = 1.1 if 10 <= hour <= 16 else 1.05 \n",
        "    else:\n",
        "        price_adjustment = 1\n",
        "    dynamic_prices.append(base_price * price_adjustment)\n",
        "\n",
        "print(dynamic_prices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrVPaLcvwSmL",
        "outputId": "19d5e31c-7bf5-4e60-e98d-6e18a1d8cdb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X shape: (4652, 3)\n",
            "hours_scaled shape: (4652, 1)\n",
            "Epoch 1/20\n",
            "117/117 - 4s - loss: 0.1210 - 4s/epoch - 34ms/step\n",
            "Epoch 2/20\n",
            "117/117 - 1s - loss: 0.0905 - 803ms/epoch - 7ms/step\n",
            "Epoch 3/20\n",
            "117/117 - 1s - loss: 0.0770 - 792ms/epoch - 7ms/step\n",
            "Epoch 4/20\n",
            "117/117 - 1s - loss: 0.0646 - 776ms/epoch - 7ms/step\n",
            "Epoch 5/20\n",
            "117/117 - 1s - loss: 0.0596 - 805ms/epoch - 7ms/step\n",
            "Epoch 6/20\n",
            "117/117 - 1s - loss: 0.0582 - 710ms/epoch - 6ms/step\n",
            "Epoch 7/20\n",
            "117/117 - 1s - loss: 0.0574 - 635ms/epoch - 5ms/step\n",
            "Epoch 8/20\n",
            "117/117 - 1s - loss: 0.0572 - 671ms/epoch - 6ms/step\n",
            "Epoch 9/20\n",
            "117/117 - 1s - loss: 0.0577 - 566ms/epoch - 5ms/step\n",
            "Epoch 10/20\n",
            "117/117 - 1s - loss: 0.0576 - 617ms/epoch - 5ms/step\n",
            "Epoch 11/20\n",
            "117/117 - 1s - loss: 0.0575 - 565ms/epoch - 5ms/step\n",
            "Epoch 12/20\n",
            "117/117 - 1s - loss: 0.0570 - 560ms/epoch - 5ms/step\n",
            "Epoch 13/20\n",
            "117/117 - 0s - loss: 0.0566 - 397ms/epoch - 3ms/step\n",
            "Epoch 14/20\n",
            "117/117 - 0s - loss: 0.0566 - 410ms/epoch - 4ms/step\n",
            "Epoch 15/20\n",
            "117/117 - 0s - loss: 0.0565 - 375ms/epoch - 3ms/step\n",
            "Epoch 16/20\n",
            "117/117 - 0s - loss: 0.0567 - 380ms/epoch - 3ms/step\n",
            "Epoch 17/20\n",
            "117/117 - 0s - loss: 0.0564 - 392ms/epoch - 3ms/step\n",
            "Epoch 18/20\n",
            "117/117 - 0s - loss: 0.0561 - 383ms/epoch - 3ms/step\n",
            "Epoch 19/20\n",
            "117/117 - 0s - loss: 0.0566 - 398ms/epoch - 3ms/step\n",
            "Epoch 20/20\n",
            "117/117 - 0s - loss: 0.0569 - 391ms/epoch - 3ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d27a89fd2d0>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "# base rate\n",
        "base_prices = {\n",
        "    'Blue Lagoon': 50,\n",
        "    'Machu Picchu': 70,\n",
        "    'Taj Mahal': 40,\n",
        "    'Doge\\'s Palace': 55,\n",
        "    'Louvre Museum': 65\n",
        "}\n",
        "\n",
        "# make data\n",
        "data = pd.read_csv('/content/drive/MyDrive/ForwardKeys_data.csv')\n",
        "data['Date'] = pd.to_datetime(data['Date'])\n",
        "data['DayOfWeek'] = data['Date'].dt.dayofweek\n",
        "data['Month'] = data['Date'].dt.month\n",
        "data['Hour'] = pd.to_datetime(data['Time'], format='%H:%M').dt.hour\n",
        "\n",
        "visitor_data = data['Visitors in Taj Mahal'].values.reshape(-1, 1)\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "visitor_scaled = scaler.fit_transform(visitor_data)\n",
        "\n",
        "# make dataset for lstm\n",
        "def create_dataset(dataset, look_back=1):\n",
        "    X, Y = [], []\n",
        "    for i in range(len(dataset) - look_back - 1):\n",
        "        a = dataset[i:(i + look_back), 0]\n",
        "        X.append(a)\n",
        "        Y.append(dataset[i + look_back, 0])\n",
        "    return np.array(X), np.array(Y)\n",
        "\n",
        "look_back = 3\n",
        "X, y = create_dataset(visitor_scaled, look_back)\n",
        "\n",
        "hours_scaled = scaler.fit_transform(data['Hour'].values.reshape(-1, 1)[look_back:-1]) \n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"hours_scaled shape:\", hours_scaled.shape)\n",
        "\n",
        "hours_scaled = hours_scaled.flatten()\n",
        "X = np.hstack((X, hours_scaled.reshape(hours_scaled.shape[0], 1)))  # Proper hstack with correct reshaping\n",
        "X = X.reshape((X.shape[0], look_back + 1, 1))\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build LSTM modle\n",
        "model = Sequential([\n",
        "    LSTM(50, input_shape=(look_back + 1, 1), activation='relu'),\n",
        "    Dense(50, activation='relu'),\n",
        "    Dense(25, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# train model\n",
        "model.fit(X_train, y_train, epochs=20, batch_size=32, verbose=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OonHY_Pwski1",
        "outputId": "ac057c0c-6648-4ccc-ff75-affd89a120ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[40, 42.0, 42.0, 40, 42.0, 40, 40, 40, 42.0, 40, 40, 40, 40, 40, 40, 40, 42.0, 40, 40, 44.0, 40, 40, 40, 40, 44.0, 40, 44.0, 40, 40, 42.0, 40, 40, 40, 40, 40, 40, 44.0, 40, 40, 44.0, 40, 40, 40, 42.0, 42.0, 40, 40, 40, 40, 40, 42.0, 40, 44.0, 40, 40, 42.0, 40, 40, 42.0, 42.0, 40, 40, 40, 44.0, 40, 40, 40, 40, 40, 40, 40, 44.0, 40, 40, 42.0, 40, 42.0, 40, 42.0, 40, 40, 40, 40, 40, 40, 40, 40, 44.0, 40, 40, 40, 42.0, 42.0, 42.0, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 42.0, 44.0, 40, 40, 44.0, 40, 40, 40, 44.0, 42.0, 44.0, 42.0, 42.0, 40, 40, 40, 40, 40, 42.0, 42.0, 40, 40, 40, 42.0, 44.0, 40, 40, 42.0, 40, 40, 40, 42.0, 40, 42.0, 40, 40, 40, 40, 44.0, 44.0, 40, 40, 40, 40, 40, 40, 40, 44.0, 40, 42.0, 40, 42.0, 40, 42.0, 42.0, 40, 40, 44.0, 44.0, 40, 44.0, 40, 40, 40, 40, 42.0, 44.0, 40, 42.0, 44.0, 40, 40, 40, 44.0, 40, 40, 40, 40, 40, 40, 40, 42.0, 40, 40, 40, 40, 40, 42.0, 44.0, 40, 40, 40, 40, 40, 42.0, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 42.0, 40, 40, 44.0, 40, 40, 40, 40, 40, 42.0, 40, 42.0, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 42.0, 42.0, 40, 40, 40, 42.0, 40, 42.0, 40, 42.0, 44.0, 42.0, 42.0, 44.0, 40, 44.0, 40, 44.0, 40, 42.0, 40, 40, 40, 40, 40, 40, 44.0, 40, 40, 40, 42.0, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 42.0, 40, 40, 42.0, 40, 40, 40, 40, 40, 40, 40, 40, 42.0, 42.0, 40, 40, 42.0, 44.0, 40, 40, 40, 40, 40, 40, 42.0, 40, 40, 40, 40, 40, 42.0, 40, 40, 42.0, 40, 40, 40, 44.0, 42.0, 44.0, 40, 40, 40, 40, 40, 42.0, 40, 40, 40, 40, 40, 42.0, 42.0, 40, 42.0, 40, 40, 40, 40, 40, 42.0, 44.0, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 42.0, 40, 40, 44.0, 40, 44.0, 40, 40, 44.0, 42.0, 42.0, 40, 44.0, 40, 40, 40, 40, 42.0, 40, 42.0, 40, 40, 40, 40, 40, 40, 40, 40, 42.0, 44.0, 40, 40, 40, 40, 44.0, 40, 44.0, 40, 42.0, 40, 40, 40, 42.0, 42.0, 40, 40, 42.0, 40, 40, 40, 40, 40, 40, 40, 42.0, 42.0, 40, 42.0, 40, 40, 40, 40, 40, 40, 40, 42.0, 40, 44.0, 40, 42.0, 40, 40, 40, 40, 40, 42.0, 42.0, 42.0, 44.0, 40, 40, 40, 40, 40, 42.0, 40, 40, 40, 40, 40, 44.0, 40, 40, 40, 40, 42.0, 42.0, 40, 42.0, 40, 44.0, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 44.0, 40, 40, 40, 44.0, 42.0, 40, 40, 40, 42.0, 40, 40, 42.0, 40, 44.0, 40, 44.0, 40, 40, 40, 40, 40, 40, 44.0, 40, 44.0, 40, 40, 40, 40, 40, 40, 40, 40, 40, 42.0, 40, 40, 40, 40, 40, 40, 40, 42.0, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 42.0, 44.0, 40, 40, 40, 42.0, 40, 40, 42.0, 40, 40, 42.0, 40, 40, 40, 40, 44.0, 40, 40, 42.0, 40, 40, 40, 40, 40, 40, 40, 42.0, 40, 40, 40, 40, 42.0, 40, 44.0, 40, 40, 44.0, 40, 40, 40, 40, 40, 40, 44.0, 40, 42.0, 40, 40, 40, 40, 40, 40, 40, 40, 40, 44.0, 42.0, 40, 40, 40, 42.0, 40, 44.0, 40, 40, 40, 40, 40, 42.0, 40, 40, 42.0, 40, 42.0, 40, 40, 40, 40, 40, 44.0, 42.0, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 42.0, 44.0, 40, 40, 44.0, 40, 42.0, 40, 40, 40, 40, 40, 42.0, 40, 42.0, 40, 40, 40, 40, 40, 42.0, 42.0, 40, 40, 42.0, 40, 42.0, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 42.0, 40, 40, 40, 40, 40, 40, 40, 40, 40, 42.0, 42.0, 40, 40, 40, 40, 40, 44.0, 40, 40, 40, 40, 42.0, 40, 40, 42.0, 40, 40, 40, 40, 40, 40, 44.0, 42.0, 42.0, 40, 40, 40, 40, 42.0, 40, 44.0, 44.0, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 42.0, 42.0, 44.0, 44.0, 40, 40, 40, 40, 44.0, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 42.0, 40, 42.0, 40, 42.0, 40, 40, 40, 40, 42.0, 40, 40, 40, 40, 42.0, 42.0, 40, 42.0, 44.0, 40, 40, 40, 40, 42.0, 40, 40, 40, 40, 40, 40, 40, 44.0, 40, 44.0, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 42.0, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 44.0, 40, 40, 40, 40, 40, 44.0, 40, 44.0, 42.0, 40, 40, 40, 40, 40, 40, 42.0, 40, 42.0, 40, 40, 40, 40, 44.0, 40, 40, 40, 42.0, 42.0, 40, 42.0, 40, 44.0, 40, 40, 40, 40, 40, 40, 44.0, 40, 40, 40, 40, 42.0, 40, 40, 40, 40, 44.0, 40, 40, 40, 40, 40, 40, 40, 42.0, 40, 42.0, 42.0, 42.0, 40, 40, 40, 40, 42.0, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 42.0, 42.0, 40, 44.0, 44.0, 40, 40, 40, 44.0, 40, 40, 40, 40, 40, 40, 40, 42.0, 40, 40, 40, 42.0, 40, 40, 40, 42.0, 40, 40, 40, 40, 44.0, 42.0, 42.0, 40, 40, 40, 40, 40, 44.0, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40]\n"
          ]
        }
      ],
      "source": [
        "# find dynamic price\n",
        "base_price = 40 \n",
        "dynamic_prices = []\n",
        "for pred, hour in zip(predictions.flatten(), test_hours):\n",
        "    if pred > np.percentile(predictions, 75):\n",
        "        price_adjustment = 1.1 if 10 <= hour <= 16 else 1.05  \n",
        "    else:\n",
        "        price_adjustment = 1  \n",
        "    dynamic_prices.append(base_price * price_adjustment)\n",
        "\n",
        "print(dynamic_prices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwkxrAHls6ed",
        "outputId": "b024bdf2-2e1b-4b4f-eeea-2bdefee90bdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X shape: (4652, 3)\n",
            "hours_scaled shape: (4652, 1)\n",
            "Epoch 1/20\n",
            "117/117 - 5s - loss: 0.1547 - 5s/epoch - 41ms/step\n",
            "Epoch 2/20\n",
            "117/117 - 1s - loss: 0.0870 - 632ms/epoch - 5ms/step\n",
            "Epoch 3/20\n",
            "117/117 - 1s - loss: 0.0835 - 634ms/epoch - 5ms/step\n",
            "Epoch 4/20\n",
            "117/117 - 1s - loss: 0.0817 - 601ms/epoch - 5ms/step\n",
            "Epoch 5/20\n",
            "117/117 - 1s - loss: 0.0807 - 628ms/epoch - 5ms/step\n",
            "Epoch 6/20\n",
            "117/117 - 1s - loss: 0.0793 - 558ms/epoch - 5ms/step\n",
            "Epoch 7/20\n",
            "117/117 - 1s - loss: 0.0787 - 513ms/epoch - 4ms/step\n",
            "Epoch 8/20\n",
            "117/117 - 1s - loss: 0.0772 - 687ms/epoch - 6ms/step\n",
            "Epoch 9/20\n",
            "117/117 - 1s - loss: 0.0770 - 854ms/epoch - 7ms/step\n",
            "Epoch 10/20\n",
            "117/117 - 1s - loss: 0.0763 - 558ms/epoch - 5ms/step\n",
            "Epoch 11/20\n",
            "117/117 - 1s - loss: 0.0761 - 581ms/epoch - 5ms/step\n",
            "Epoch 12/20\n",
            "117/117 - 1s - loss: 0.0759 - 523ms/epoch - 4ms/step\n",
            "Epoch 13/20\n",
            "117/117 - 1s - loss: 0.0769 - 565ms/epoch - 5ms/step\n",
            "Epoch 14/20\n",
            "117/117 - 1s - loss: 0.0761 - 503ms/epoch - 4ms/step\n",
            "Epoch 15/20\n",
            "117/117 - 1s - loss: 0.0759 - 633ms/epoch - 5ms/step\n",
            "Epoch 16/20\n",
            "117/117 - 1s - loss: 0.0762 - 709ms/epoch - 6ms/step\n",
            "Epoch 17/20\n",
            "117/117 - 1s - loss: 0.0758 - 791ms/epoch - 7ms/step\n",
            "Epoch 18/20\n",
            "117/117 - 1s - loss: 0.0760 - 858ms/epoch - 7ms/step\n",
            "Epoch 19/20\n",
            "117/117 - 1s - loss: 0.0762 - 814ms/epoch - 7ms/step\n",
            "Epoch 20/20\n",
            "117/117 - 1s - loss: 0.0756 - 985ms/epoch - 8ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d27a89e8610>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "# base price\n",
        "base_prices = {\n",
        "    'Blue Lagoon': 50,\n",
        "    'Machu Picchu': 70,\n",
        "    'Taj Mahal': 40,\n",
        "    'Doge\\'s Palace': 55,\n",
        "    'Louvre Museum': 65\n",
        "}\n",
        "\n",
        "# make data\n",
        "data = pd.read_csv('/content/drive/MyDrive/ForwardKeys_data.csv')\n",
        "data['Date'] = pd.to_datetime(data['Date'])\n",
        "data['DayOfWeek'] = data['Date'].dt.dayofweek\n",
        "data['Month'] = data['Date'].dt.month\n",
        "data['Hour'] = pd.to_datetime(data['Time'], format='%H:%M').dt.hour\n",
        "\n",
        "visitor_data = data['Visitors in Doge\\'s Palace'].values.reshape(-1, 1)\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "visitor_scaled = scaler.fit_transform(visitor_data)\n",
        "\n",
        "# make dataset \n",
        "def create_dataset(dataset, look_back=1):\n",
        "    X, Y = [], []\n",
        "    for i in range(len(dataset) - look_back - 1):\n",
        "        a = dataset[i:(i + look_back), 0]\n",
        "        X.append(a)\n",
        "        Y.append(dataset[i + look_back, 0])\n",
        "    return np.array(X), np.array(Y)\n",
        "\n",
        "look_back = 3\n",
        "X, y = create_dataset(visitor_scaled, look_back)\n",
        "\n",
        "hours_scaled = scaler.fit_transform(data['Hour'].values.reshape(-1, 1)[look_back:-1])  # Adjust slicing to align with X\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"hours_scaled shape:\", hours_scaled.shape)\n",
        "\n",
        "hours_scaled = hours_scaled.flatten()\n",
        "X = np.hstack((X, hours_scaled.reshape(hours_scaled.shape[0], 1)))  # Proper hstack with correct reshaping\n",
        "X = X.reshape((X.shape[0], look_back + 1, 1))\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build the LSTM model\n",
        "model = Sequential([\n",
        "    LSTM(50, input_shape=(look_back + 1, 1), activation='relu'),\n",
        "    Dense(50, activation='relu'),\n",
        "    Dense(25, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# train\n",
        "model.fit(X_train, y_train, epochs=20, batch_size=32, verbose=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGuTBzVBssGG",
        "outputId": "bf3cfe0b-2917-4d03-c63e-a47733910b88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[55, 57.75, 57.75, 55, 57.75, 55, 55, 55, 57.75, 55, 55, 55, 55, 55, 55, 55, 57.75, 55, 55, 60.50000000000001, 55, 55, 55, 55, 60.50000000000001, 55, 60.50000000000001, 55, 55, 57.75, 55, 55, 55, 55, 55, 55, 60.50000000000001, 55, 55, 60.50000000000001, 55, 55, 55, 57.75, 57.75, 55, 55, 55, 55, 55, 57.75, 55, 60.50000000000001, 55, 55, 57.75, 55, 55, 57.75, 57.75, 55, 55, 55, 60.50000000000001, 55, 55, 55, 55, 55, 55, 55, 60.50000000000001, 55, 55, 57.75, 55, 57.75, 55, 57.75, 55, 55, 55, 55, 55, 55, 55, 55, 60.50000000000001, 55, 55, 55, 57.75, 57.75, 57.75, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 57.75, 60.50000000000001, 55, 55, 60.50000000000001, 55, 55, 55, 60.50000000000001, 57.75, 60.50000000000001, 57.75, 57.75, 55, 55, 55, 55, 55, 57.75, 57.75, 55, 55, 55, 57.75, 60.50000000000001, 55, 55, 57.75, 55, 55, 55, 57.75, 55, 57.75, 55, 55, 55, 55, 60.50000000000001, 60.50000000000001, 55, 55, 55, 55, 55, 55, 55, 60.50000000000001, 55, 57.75, 55, 57.75, 55, 57.75, 57.75, 55, 55, 60.50000000000001, 60.50000000000001, 55, 60.50000000000001, 55, 55, 55, 55, 57.75, 60.50000000000001, 55, 57.75, 60.50000000000001, 55, 55, 55, 60.50000000000001, 55, 55, 55, 55, 55, 55, 55, 57.75, 55, 55, 55, 55, 55, 57.75, 60.50000000000001, 55, 55, 55, 55, 55, 57.75, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 57.75, 55, 55, 60.50000000000001, 55, 55, 55, 55, 55, 57.75, 55, 57.75, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 57.75, 57.75, 55, 55, 55, 57.75, 55, 57.75, 55, 57.75, 60.50000000000001, 57.75, 57.75, 60.50000000000001, 55, 60.50000000000001, 55, 60.50000000000001, 55, 57.75, 55, 55, 55, 55, 55, 55, 60.50000000000001, 55, 55, 55, 57.75, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 57.75, 55, 55, 57.75, 55, 55, 55, 55, 55, 55, 55, 55, 57.75, 57.75, 55, 55, 57.75, 60.50000000000001, 55, 55, 55, 55, 55, 55, 57.75, 55, 55, 55, 55, 55, 57.75, 55, 55, 57.75, 55, 55, 55, 60.50000000000001, 57.75, 60.50000000000001, 55, 55, 55, 55, 55, 57.75, 55, 55, 55, 55, 55, 57.75, 57.75, 55, 57.75, 55, 55, 55, 55, 55, 57.75, 60.50000000000001, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 57.75, 55, 55, 60.50000000000001, 55, 60.50000000000001, 55, 55, 60.50000000000001, 57.75, 57.75, 55, 60.50000000000001, 55, 55, 55, 55, 57.75, 55, 57.75, 55, 55, 55, 55, 55, 55, 55, 55, 57.75, 60.50000000000001, 55, 55, 55, 55, 60.50000000000001, 55, 60.50000000000001, 55, 57.75, 55, 55, 55, 57.75, 57.75, 55, 55, 57.75, 55, 55, 55, 55, 55, 55, 55, 57.75, 57.75, 55, 57.75, 55, 55, 55, 55, 55, 55, 55, 57.75, 55, 60.50000000000001, 55, 57.75, 55, 55, 55, 55, 55, 57.75, 57.75, 57.75, 60.50000000000001, 55, 55, 55, 55, 55, 57.75, 55, 55, 55, 55, 55, 60.50000000000001, 55, 55, 55, 55, 57.75, 57.75, 55, 57.75, 55, 60.50000000000001, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 60.50000000000001, 55, 55, 55, 60.50000000000001, 57.75, 55, 55, 55, 57.75, 55, 55, 57.75, 55, 60.50000000000001, 55, 60.50000000000001, 55, 55, 55, 55, 55, 55, 60.50000000000001, 55, 60.50000000000001, 55, 55, 55, 55, 55, 55, 55, 55, 55, 57.75, 55, 55, 55, 55, 55, 55, 55, 57.75, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 57.75, 60.50000000000001, 55, 55, 55, 57.75, 55, 55, 57.75, 55, 55, 57.75, 55, 55, 55, 55, 60.50000000000001, 55, 55, 57.75, 55, 55, 55, 55, 55, 55, 55, 57.75, 55, 55, 55, 55, 57.75, 55, 60.50000000000001, 55, 55, 60.50000000000001, 55, 55, 55, 55, 55, 55, 60.50000000000001, 55, 57.75, 55, 55, 55, 55, 55, 55, 55, 55, 55, 60.50000000000001, 57.75, 55, 55, 55, 57.75, 55, 60.50000000000001, 55, 55, 55, 55, 55, 57.75, 55, 55, 57.75, 55, 57.75, 55, 55, 55, 55, 55, 60.50000000000001, 57.75, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 57.75, 60.50000000000001, 55, 55, 60.50000000000001, 55, 57.75, 55, 55, 55, 55, 55, 57.75, 55, 57.75, 55, 55, 55, 55, 55, 57.75, 57.75, 55, 55, 57.75, 55, 57.75, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 57.75, 55, 55, 55, 55, 55, 55, 55, 55, 55, 57.75, 57.75, 55, 55, 55, 55, 55, 60.50000000000001, 55, 55, 55, 55, 57.75, 55, 55, 57.75, 55, 55, 55, 55, 55, 55, 60.50000000000001, 57.75, 57.75, 55, 55, 55, 55, 57.75, 55, 60.50000000000001, 60.50000000000001, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 57.75, 57.75, 60.50000000000001, 60.50000000000001, 55, 55, 55, 55, 60.50000000000001, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 57.75, 55, 57.75, 55, 57.75, 55, 55, 55, 55, 57.75, 55, 55, 55, 55, 57.75, 57.75, 55, 57.75, 60.50000000000001, 55, 55, 55, 55, 57.75, 55, 55, 55, 55, 55, 55, 55, 60.50000000000001, 55, 60.50000000000001, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 57.75, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 60.50000000000001, 55, 55, 55, 55, 55, 60.50000000000001, 55, 60.50000000000001, 57.75, 55, 55, 55, 55, 55, 55, 57.75, 55, 57.75, 55, 55, 55, 55, 60.50000000000001, 55, 55, 55, 57.75, 57.75, 55, 57.75, 55, 60.50000000000001, 55, 55, 55, 55, 55, 55, 60.50000000000001, 55, 55, 55, 55, 57.75, 55, 55, 55, 55, 60.50000000000001, 55, 55, 55, 55, 55, 55, 55, 57.75, 55, 57.75, 57.75, 57.75, 55, 55, 55, 55, 57.75, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 57.75, 57.75, 55, 60.50000000000001, 60.50000000000001, 55, 55, 55, 60.50000000000001, 55, 55, 55, 55, 55, 55, 55, 57.75, 55, 55, 55, 57.75, 55, 55, 55, 57.75, 55, 55, 55, 55, 60.50000000000001, 57.75, 57.75, 55, 55, 55, 55, 55, 60.50000000000001, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55]\n"
          ]
        }
      ],
      "source": [
        "#doge's palace\n",
        "base_price = 55  \n",
        "dynamic_prices = []\n",
        "for pred, hour in zip(predictions.flatten(), test_hours):\n",
        "    if pred > np.percentile(predictions, 75):\n",
        "        price_adjustment = 1.1 if 10 <= hour <= 16 else 1.05  \n",
        "    else:\n",
        "        price_adjustment = 1 \n",
        "    dynamic_prices.append(base_price * price_adjustment)\n",
        "\n",
        "print(dynamic_prices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqSrJFCbw_Jo",
        "outputId": "d8a71a3f-130a-4b8d-d515-df4d9b4c5142"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X shape: (4652, 3)\n",
            "hours_scaled shape: (4652, 1)\n",
            "Epoch 1/20\n",
            "117/117 - 4s - loss: 0.1680 - 4s/epoch - 34ms/step\n",
            "Epoch 2/20\n",
            "117/117 - 1s - loss: 0.0577 - 627ms/epoch - 5ms/step\n",
            "Epoch 3/20\n",
            "117/117 - 1s - loss: 0.0453 - 563ms/epoch - 5ms/step\n",
            "Epoch 4/20\n",
            "117/117 - 1s - loss: 0.0356 - 650ms/epoch - 6ms/step\n",
            "Epoch 5/20\n",
            "117/117 - 1s - loss: 0.0258 - 607ms/epoch - 5ms/step\n",
            "Epoch 6/20\n",
            "117/117 - 1s - loss: 0.0243 - 536ms/epoch - 5ms/step\n",
            "Epoch 7/20\n",
            "117/117 - 1s - loss: 0.0233 - 619ms/epoch - 5ms/step\n",
            "Epoch 8/20\n",
            "117/117 - 1s - loss: 0.0235 - 587ms/epoch - 5ms/step\n",
            "Epoch 9/20\n",
            "117/117 - 1s - loss: 0.0232 - 584ms/epoch - 5ms/step\n",
            "Epoch 10/20\n",
            "117/117 - 1s - loss: 0.0238 - 611ms/epoch - 5ms/step\n",
            "Epoch 11/20\n",
            "117/117 - 1s - loss: 0.0235 - 584ms/epoch - 5ms/step\n",
            "Epoch 12/20\n",
            "117/117 - 0s - loss: 0.0234 - 379ms/epoch - 3ms/step\n",
            "Epoch 13/20\n",
            "117/117 - 0s - loss: 0.0231 - 455ms/epoch - 4ms/step\n",
            "Epoch 14/20\n",
            "117/117 - 0s - loss: 0.0232 - 396ms/epoch - 3ms/step\n",
            "Epoch 15/20\n",
            "117/117 - 0s - loss: 0.0231 - 407ms/epoch - 3ms/step\n",
            "Epoch 16/20\n",
            "117/117 - 0s - loss: 0.0230 - 420ms/epoch - 4ms/step\n",
            "Epoch 17/20\n",
            "117/117 - 1s - loss: 0.0230 - 568ms/epoch - 5ms/step\n",
            "Epoch 18/20\n",
            "117/117 - 1s - loss: 0.0232 - 582ms/epoch - 5ms/step\n",
            "Epoch 19/20\n",
            "117/117 - 1s - loss: 0.0232 - 586ms/epoch - 5ms/step\n",
            "Epoch 20/20\n",
            "117/117 - 1s - loss: 0.0230 - 591ms/epoch - 5ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d27a1a1d660>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "# Assume base prices\n",
        "base_prices = {\n",
        "    'Blue Lagoon': 50,\n",
        "    'Machu Picchu': 70,\n",
        "    'Taj Mahal': 40,\n",
        "    'Doge\\'s Palace': 55,\n",
        "    'Louvre Museum': 65\n",
        "}\n",
        "\n",
        "# make dataset\n",
        "data = pd.read_csv('/content/drive/MyDrive/ForwardKeys_data.csv')\n",
        "data['Date'] = pd.to_datetime(data['Date'])\n",
        "data['DayOfWeek'] = data['Date'].dt.dayofweek\n",
        "data['Month'] = data['Date'].dt.month\n",
        "data['Hour'] = pd.to_datetime(data['Time'], format='%H:%M').dt.hour\n",
        "\n",
        "\n",
        "visitor_data = data['Visitors in Louvre Museum'].values.reshape(-1, 1)\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "visitor_scaled = scaler.fit_transform(visitor_data)\n",
        "\n",
        "# Create dataset\n",
        "def create_dataset(dataset, look_back=1):\n",
        "    X, Y = [], []\n",
        "    for i in range(len(dataset) - look_back - 1):\n",
        "        a = dataset[i:(i + look_back), 0]\n",
        "        X.append(a)\n",
        "        Y.append(dataset[i + look_back, 0])\n",
        "    return np.array(X), np.array(Y)\n",
        "\n",
        "look_back = 3\n",
        "X, y = create_dataset(visitor_scaled, look_back)\n",
        "\n",
        "# Include hour of day as a feature\n",
        "hours_scaled = scaler.fit_transform(data['Hour'].values.reshape(-1, 1)[look_back:-1]) \n",
        "\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"hours_scaled shape:\", hours_scaled.shape)\n",
        "\n",
        "hours_scaled = hours_scaled.flatten()\n",
        "\n",
        "X = np.hstack((X, hours_scaled.reshape(hours_scaled.shape[0], 1)))  # Proper hstack with correct reshaping\n",
        "X = X.reshape((X.shape[0], look_back + 1, 1))\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# make lstm model\n",
        "model = Sequential([\n",
        "    LSTM(50, input_shape=(look_back + 1, 1), activation='relu'),\n",
        "    Dense(50, activation='relu'),\n",
        "    Dense(25, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# train\n",
        "model.fit(X_train, y_train, epochs=20, batch_size=32, verbose=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzsbKnW8szwL",
        "outputId": "e47d49a4-c0db-46d8-d5b9-5171faefef99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[65, 68.25, 68.25, 65, 68.25, 65, 65, 65, 68.25, 65, 65, 65, 65, 65, 65, 65, 68.25, 65, 65, 71.5, 65, 65, 65, 65, 71.5, 65, 71.5, 65, 65, 68.25, 65, 65, 65, 65, 65, 65, 71.5, 65, 65, 71.5, 65, 65, 65, 68.25, 68.25, 65, 65, 65, 65, 65, 68.25, 65, 71.5, 65, 65, 68.25, 65, 65, 68.25, 68.25, 65, 65, 65, 71.5, 65, 65, 65, 65, 65, 65, 65, 71.5, 65, 65, 68.25, 65, 68.25, 65, 68.25, 65, 65, 65, 65, 65, 65, 65, 65, 71.5, 65, 65, 65, 68.25, 68.25, 68.25, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 68.25, 71.5, 65, 65, 71.5, 65, 65, 65, 71.5, 68.25, 71.5, 68.25, 68.25, 65, 65, 65, 65, 65, 68.25, 68.25, 65, 65, 65, 68.25, 71.5, 65, 65, 68.25, 65, 65, 65, 68.25, 65, 68.25, 65, 65, 65, 65, 71.5, 71.5, 65, 65, 65, 65, 65, 65, 65, 71.5, 65, 68.25, 65, 68.25, 65, 68.25, 68.25, 65, 65, 71.5, 71.5, 65, 71.5, 65, 65, 65, 65, 68.25, 71.5, 65, 68.25, 71.5, 65, 65, 65, 71.5, 65, 65, 65, 65, 65, 65, 65, 68.25, 65, 65, 65, 65, 65, 68.25, 71.5, 65, 65, 65, 65, 65, 68.25, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 68.25, 65, 65, 71.5, 65, 65, 65, 65, 65, 68.25, 65, 68.25, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 68.25, 68.25, 65, 65, 65, 68.25, 65, 68.25, 65, 68.25, 71.5, 68.25, 68.25, 71.5, 65, 71.5, 65, 71.5, 65, 68.25, 65, 65, 65, 65, 65, 65, 71.5, 65, 65, 65, 68.25, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 68.25, 65, 65, 68.25, 65, 65, 65, 65, 65, 65, 65, 65, 68.25, 68.25, 65, 65, 68.25, 71.5, 65, 65, 65, 65, 65, 65, 68.25, 65, 65, 65, 65, 65, 68.25, 65, 65, 68.25, 65, 65, 65, 71.5, 68.25, 71.5, 65, 65, 65, 65, 65, 68.25, 65, 65, 65, 65, 65, 68.25, 68.25, 65, 68.25, 65, 65, 65, 65, 65, 68.25, 71.5, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 68.25, 65, 65, 71.5, 65, 71.5, 65, 65, 71.5, 68.25, 68.25, 65, 71.5, 65, 65, 65, 65, 68.25, 65, 68.25, 65, 65, 65, 65, 65, 65, 65, 65, 68.25, 71.5, 65, 65, 65, 65, 71.5, 65, 71.5, 65, 68.25, 65, 65, 65, 68.25, 68.25, 65, 65, 68.25, 65, 65, 65, 65, 65, 65, 65, 68.25, 68.25, 65, 68.25, 65, 65, 65, 65, 65, 65, 65, 68.25, 65, 71.5, 65, 68.25, 65, 65, 65, 65, 65, 68.25, 68.25, 68.25, 71.5, 65, 65, 65, 65, 65, 68.25, 65, 65, 65, 65, 65, 71.5, 65, 65, 65, 65, 68.25, 68.25, 65, 68.25, 65, 71.5, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 71.5, 65, 65, 65, 71.5, 68.25, 65, 65, 65, 68.25, 65, 65, 68.25, 65, 71.5, 65, 71.5, 65, 65, 65, 65, 65, 65, 71.5, 65, 71.5, 65, 65, 65, 65, 65, 65, 65, 65, 65, 68.25, 65, 65, 65, 65, 65, 65, 65, 68.25, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 68.25, 71.5, 65, 65, 65, 68.25, 65, 65, 68.25, 65, 65, 68.25, 65, 65, 65, 65, 71.5, 65, 65, 68.25, 65, 65, 65, 65, 65, 65, 65, 68.25, 65, 65, 65, 65, 68.25, 65, 71.5, 65, 65, 71.5, 65, 65, 65, 65, 65, 65, 71.5, 65, 68.25, 65, 65, 65, 65, 65, 65, 65, 65, 65, 71.5, 68.25, 65, 65, 65, 68.25, 65, 71.5, 65, 65, 65, 65, 65, 68.25, 65, 65, 68.25, 65, 68.25, 65, 65, 65, 65, 65, 71.5, 68.25, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 68.25, 71.5, 65, 65, 71.5, 65, 68.25, 65, 65, 65, 65, 65, 68.25, 65, 68.25, 65, 65, 65, 65, 65, 68.25, 68.25, 65, 65, 68.25, 65, 68.25, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 68.25, 65, 65, 65, 65, 65, 65, 65, 65, 65, 68.25, 68.25, 65, 65, 65, 65, 65, 71.5, 65, 65, 65, 65, 68.25, 65, 65, 68.25, 65, 65, 65, 65, 65, 65, 71.5, 68.25, 68.25, 65, 65, 65, 65, 68.25, 65, 71.5, 71.5, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 68.25, 68.25, 71.5, 71.5, 65, 65, 65, 65, 71.5, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 68.25, 65, 68.25, 65, 68.25, 65, 65, 65, 65, 68.25, 65, 65, 65, 65, 68.25, 68.25, 65, 68.25, 71.5, 65, 65, 65, 65, 68.25, 65, 65, 65, 65, 65, 65, 65, 71.5, 65, 71.5, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 68.25, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 71.5, 65, 65, 65, 65, 65, 71.5, 65, 71.5, 68.25, 65, 65, 65, 65, 65, 65, 68.25, 65, 68.25, 65, 65, 65, 65, 71.5, 65, 65, 65, 68.25, 68.25, 65, 68.25, 65, 71.5, 65, 65, 65, 65, 65, 65, 71.5, 65, 65, 65, 65, 68.25, 65, 65, 65, 65, 71.5, 65, 65, 65, 65, 65, 65, 65, 68.25, 65, 68.25, 68.25, 68.25, 65, 65, 65, 65, 68.25, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 68.25, 68.25, 65, 71.5, 71.5, 65, 65, 65, 71.5, 65, 65, 65, 65, 65, 65, 65, 68.25, 65, 65, 65, 68.25, 65, 65, 65, 68.25, 65, 65, 65, 65, 71.5, 68.25, 68.25, 65, 65, 65, 65, 65, 71.5, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65]\n"
          ]
        }
      ],
      "source": [
        "# Calculate dynamic prices based on predictions and time\n",
        "base_price = 65  # Base price for 'Louvre Museum'\n",
        "dynamic_prices = []\n",
        "for pred, hour in zip(predictions.flatten(), test_hours):\n",
        "    if pred > np.percentile(predictions, 75):\n",
        "        price_adjustment = 1.1 if 10 <= hour <= 16 else 1.05  # 10% increase during peak hours, 5% during off-peak\n",
        "    else:\n",
        "        price_adjustment = 1  # No change in price\n",
        "    dynamic_prices.append(base_price * price_adjustment)\n",
        "\n",
        "print(dynamic_prices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GIy_JuhSwtD-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
